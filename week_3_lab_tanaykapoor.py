# -*- coding: utf-8 -*-
"""Week 3 Lab_TanayKapoor.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oGAn-fXPBZT0WG7MeHI6XsmS40xHwpXJ

# Week 3 Lab - due by 11:59pm CDT on July 23rd

## Objective: to implement machine learning methods and models on regression problems

### Setup and Loading Packages
"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline

import numpy as np
import pandas as pd

import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.preprocessing import scale
from sklearn.model_selection import train_test_split

import statsmodels.api as sm
from sklearn.preprocessing import StandardScaler

from sklearn.ensemble import RandomForestRegressor
from statsmodels.stats.outliers_influence import variance_inflation_factor


from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV, ElasticNetCV
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

"""## Problem 1: Real GDP Growth Rate Predictions by Country

Gross Domestic Products (GDP) growth has been a hot topic in macroeconomics and an economist on your team needs your help to uncover its implications from a statistical perspective. The economist gathered some data from the U.S. Bureau of Economic Analysis (BEA) and OECDâ€™s Composite Leading Indicators (CLIs) repositories. The U.S. BEA stores macro and micro-economic measures on a multinational level as the OECD CLIs screens the conditions that dictates the economic booms and busts of OECD countries. <br><br>

4 indictors are gathered from each of the 10 selected OECD countries: monthly real income, employment, industrial production, and wholesale-retail sales. The countries include the United States, United Kingdom, Netherlands, Luxembourg, Japan, Korea, Germany, France, Denmark, and Canada. The data are collected for over 240 months (20 years), from October 1999 to September 2019, so there is a total of 2400 observations. <br><br>

The economist wants to examine the predictive power of these features in a linear model that forecasts the real Gross Domestic Products (GDP) growth rate for each country.

*Ensure your path is correct when loading in the data. For example, if your 'OECD_DATA.csv' file is in your downloads folder, then run pd.read_csv('downloads/OECD_DATA.csv'). In this case, my .csv file in the the same path as this jupyter notebook, so I just have to call pd.read_csv('OECD_DATA.csv').
"""

from google.colab import drive
drive.mount('/content/drive')

# loading the csv data set from local directory
OECD = pd.read_csv('/content/drive/MyDrive/DSQFRM/Week 3/OECD_DATA.csv'); OECD = OECD.set_index('Date')
OECD.info()

"""a) Based on the economist's specified problem, please identify the explanatory and response variables in the data set.

[Write your answer here]

The response variable (dependent variable) is the variable or outcome that we are trying to predict. The response variable depends upon the explanatory variable(s). Explanatory variables (independent variables) are the variables, predictors, features, etc, that we use to predict outcomes (the response variable). In this case, the response variable is the real Gross Domestic Products (GDP) growth rate for each country. The explanatory variables are monthly real income (income adjusted for inflation), unemployment rate, industrial production, and wholesale-retail sales.

b) To make sure the units of the features are aligned, please write a code piece to standardize the numerical features. (Note we cannot standardize categorical features)
"""

################ EDIT CODE LINES HERE #################
# Standardizing ONLY the numerical features
# We standardize the features so all indicators have mean 0 standard deviation of 1. We standardize the features mainly because they have different units of measure (e.g.,yield curve is in %, real GDP is in billions of dollars). We scale them so that they can have the same unit.

OECD = OECD.dropna() # drop nan values from any of the rows

print('Not standardized')
print('')
print(OECD)

# variable names
FEATURES = ['realPersInc', 'unempRate', 'indProd', 'retailSales']
# predictors for our models


OECD.loc[:, FEATURES] = scale(OECD.loc[:, FEATURES]) # standardizing indicators
# scale() function (usually imported from sklearn.preprocessing) performs standardization on the data, which means it transforms the data such that each feature has a mean of 0 and a standard deviation of 1. This is also known as z-score normalization

print('')
print('Standardized Numerical Features')
print('')
print(OECD)

######################################################

"""c)<br><br>
Notice that since the Country variable is a categoirical variable, we need to use some kind of numeric indicator to replace the string values in that column. One option is to use dummy variables. A dummy variable is a binary variable that indicates whether a categorical variable takes on a specific value. For example, we will add 9 columns  to the data set and name column by the syntax 'Country_[country name]'. Each column will only take on the values 0 or 1; 0 represents that the observation on that row does not belong to the country and 1 represents that the observation on that row belongs to the country. For example, the rows where the Country value is 'USA' will have the Country_USA column being 1, and the Country_Denmark, Country_France, and so on columns being 0. <br><br>

You may ask why we added 9 columns when there are 10 countries in our original data set. This is because when all 9 dummy variables are set to 0, the regression output will represent the result for the country that doesn't have its own added column. <br><br>

Read this blog for more details: https://abbynyakara.medium.com/dummy-variables-in-machine-learning-b3991367bd59
<p style="color:red;">PLEASE DO NOT CHANGE THIS CODE !!!</p>
"""

# declaring dummy variables based on the Country column
OECD = pd.get_dummies(data=OECD, drop_first=True)
# display top rows of the new data set
OECD.head()

"""Run the above code chunk and observe that the new columns are added to the original data frame to represent the dummy variables."""

# Define the features and the response variable
RESPONSE = 'realGdpRate' # response
FEATURES = OECD.columns[1:5] # total features
#print(OECD)
print(FEATURES)
column_names = OECD.columns
print(column_names)

"""Now, write a code piece to remove potential outliers of ONLY the numerical features (values that lie more than 3 standard deviations away from the mean). How many records did you remove?"""

FEATURES = ['realPersInc', 'unempRate', 'indProd', 'retailSales']

################ EDIT CODE LINES HERE #################
# Function to remove outlying values that lie > 3 standard deviations away from the mean

# Function to remove outlying values that lie > 3 standard deviations away from the mean
def remove_outliers(df, columns, n_std):
    for col in columns:
        print('Working on column: {}'.format(col))

        mean = df[col].mean() # mean
        sd = df[col].std() # standard deviation

        df = df[(df[col] <= mean+(n_std*sd))] # criteria

    return df


######################################################

################ EDIT CODE LINES HERE #################
# Output data info after removing potential outliers
OECD1 = remove_outliers(OECD, FEATURES, 3)
OECD1.info()

######################################################

def find_outliers(df, cleaned_df, columns):
    outliers = {}  # Create a dictionary to store outliers for each column

    for col in columns:
        # Extract the original values and cleaned values for the current column
        original_values = df[col]
        cleaned_values = cleaned_df[col]

        # Find the rows where the original values and cleaned values differ (indicating outliers)
        outlier_indices = original_values[~original_values.isin(cleaned_values)].index

        # Add the outlier indices to the dictionary with the column name as the key
        outliers[col] = outlier_indices

        # Display the number of outliers removed for the current column
        num_outliers_removed = len(outlier_indices)
        print(f"Number of outliers removed from '{col}': {num_outliers_removed}")

    return outliers

# Assuming you have already defined the function 'remove_outliers' and the DataFrame 'OECD'
# (as shown in your previous code)

# Remove outliers from the 'OECD' DataFrame using the 'remove_outliers' function
OECD1 = remove_outliers(OECD, FEATURES, 3)

# Find the outliers that were removed and display the number of outliers removed for each column
removed_outliers = find_outliers(OECD, OECD1, FEATURES)

"""[Write your answer here]

The code above outputs the amount of outliers removed. The number of outliers removed from the column with the highest count will give the overall count of the highest number of outliers removed. That would be 26 outliers. Another way to confirm this is finding the original and final number of entries. Initially, I had 2399 entries, but ended with 2145 entries. 2399 - 2373 = 26 entries, so the code checks out.

d) <br><br>You want to let the economist know whether the features are important enough to predict the GDP growth rate. <br><br>Please find the feature importance score for ONLY the numberical features, and drop the features that has low importance scores (<0.05). <br><br>Please EXCLUDE dummy features for this analysis as they serve as flags to filter to a particular country.<br><br>
How many features did you drop?
"""

################ EDIT CODE LINES HERE #################
# Split data into 80% training set and 20% testing set

X_train, X_test, y_train, y_test = train_test_split(OECD1.loc[:, FEATURES], OECD1.loc[:, RESPONSE], test_size=0.2, random_state=0)


######################################################

################ EDIT CODE LINES HERE #################
# Calculate feature importance here

from sklearn.ensemble import RandomForestRegressor # importing the random forest module

rf_model = RandomForestRegressor(random_state=0) # define the random forest model

rf_model.fit(X_train, y_train) # fit the random forest model

importances = rf_model.feature_importances_ # get importance

indices = np.argsort(importances) # sort the features' index by their importance scores




######################################################

################ EDIT CODE LINES HERE #################
# Bar plot to ank feature importance here


plt.title('Feature Importances in the Random Forest Model')
plt.barh(range(len(indices)), importances[indices], align='center')
plt.yticks(range(len(indices)), [FEATURES[i] for i in indices])
plt.xlabel('Importance Score')


######################################################

"""[Write your answer here]

I did not drop any features as they all had an importance score greater than 0.05 after fitting them to the Random Forest Regression model. The 80-20 train-test split did not include the dummy variables.

e) <br><br>You want to also let the economist know whether the multicollinearity existis amongst the numerical features. This is to determine whether linear model assumptions are met before we feed in the data.<br><br> Please find the correlation or variance inflation factors (VIF) for ONLY the numberical features, and drop the features that has high correlation (>0.8) or high VIF (>5) <br><br>Please EXCLUDE dummy features for this analysis as they serve as flags to filter to a particular country.<br><br>

How many features did you remove?
"""

################ EDIT CODE LINES HERE #################
# Correaltion heatmap to identify high correlations b/w features


# plotting a correaltion heatmap to identify correlations b/w features
sns.heatmap(OECD1.loc[:, FEATURES].corr(), annot=True)
plt.title("Correlations Between Features")


######################################################

################ EDIT CODE LINES HERE #################
# Compute VIF to identify high correlations b/w features


from statsmodels.stats.outliers_influence import variance_inflation_factor
pd.DataFrame({'Features': FEATURES, 'VIF': [variance_inflation_factor(OECD1.loc[:, FEATURES].values, i) for i in range(len(FEATURES))]})



######################################################

"""[Write your answer here]

Again, I did not remove any features. None of them were positively correlated or had a correlation score of greater than 0.8. Also, the VIFs are all fairly low and none are greater than 5, so I will not drop any features.

f) Please wirte a code piece to fit a Multiple Linear Regression to the data, then print the resulting Adjusted R-squared, MAE, and RMSE metrics.
"""

# Split data into 80% training set and 20% testing set; training using dummy variables too

X_train, X_test, y_train, y_test = train_test_split(OECD1.iloc[:, 1:], OECD1.iloc[:, 0], test_size=0.2, random_state=0)

################ EDIT CODE LINES HERE #################
# Fit multiple linear regression model

linear_model = LinearRegression()

#fit regression model
linear_model = linear_model.fit(X_train, y_train)

#get estimated intercepts and coefficients
print('intercept: ', linear_model.intercept_)
print('coefficients: ', linear_model.coef_)


######################################################

################ EDIT CODE LINES HERE #################

# Model predictions

from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# Model predictions
y_test_pred_multi = linear_model.predict(X_test)
r2_multi = r2_score(y_test, y_test_pred_multi)
adj_r2_multi = 1 - (1-r2_multi) * (len(y_test)-1)/(len(y_test)-X_test.shape[1]-1)
mae_multi = mean_absolute_error(y_test, y_test_pred_multi)
rmse_multi = mean_squared_error(y_test, y_test_pred_multi, squared=False)

# Print model performance metrics
print('R-squared: ', r2_multi)
print('Adjusted R-squared: ', adj_r2_multi)
print('MAE: ', mae_multi)
print('RMSE: ', rmse_multi)

######################################################

"""g) Please wirte a code piece to fit a Lasso Regression to the data, then print the resulting Adjusted R-squared, MAE, and RMSE metrics."""

################ EDIT CODE LINES HERE #################
# Fit lasso regression model

from sklearn.linear_model import LassoCV
# initiate 5-Fold cross validation
lasso_model = LassoCV(cv=5) # uses scoring='r2'by default
# fit the model with the best alpha
lasso_model = lasso_model.fit(X_train, y_train)
print('The optimal lambda is:', lasso_model.alpha_)


######################################################

################ EDIT CODE LINES HERE #################



# Model predictions
y_test_pred_lasso = lasso_model.predict(X_test)
r2_lasso = r2_score(y_test, y_test_pred_lasso)
adj_r2_lasso = 1 - (1-r2_lasso) * (len(y_test)-1)/(len(y_test)-X_test.shape[1]-1)
mae_lasso = mean_absolute_error(y_test, y_test_pred_lasso)
rmse_lasso = mean_squared_error(y_test, y_test_pred_lasso, squared=False)

# Print model performance metrics
print('R-squared: ', r2_lasso)
print('Adjusted R-squared: ', adj_r2_lasso)
print('The MAE is: ', mae_lasso)
print('The RMSE is: ', rmse_lasso)




######################################################

"""h) Please wirte a code piece to fit a Ridge Regression to the data, then print the resulting Adjusted R-squared, MAE, and RMSE metrics."""

################ EDIT CODE LINES HERE #################
# Fit ridge regression model



from sklearn.linear_model import RidgeCV
# initiate the 5-Fold cross validation
ridge_model = RidgeCV(cv=5, scoring='r2')
# fit the model with the best alpha
ridge_model = ridge_model.fit(X_train, y_train)
print('The optimal lambda is:', ridge_model.alpha_)


######################################################

################ EDIT CODE LINES HERE #################

# Model predictions
y_test_pred_ridge = ridge_model.predict(X_test)
r2_ridge = r2_score(y_test, y_test_pred_ridge)
adj_r2_ridge = 1 - (1-r2_ridge) * (len(y_test)-1)/(len(y_test)-X_test.shape[1]-1)
mae_ridge = mean_absolute_error(y_test, y_test_pred_ridge)
rmse_ridge = mean_squared_error(y_test, y_test_pred_ridge, squared=False)

# Print model performance metrics
print('R-squared: ', r2_ridge)
print('Adjusted R-squared: ', adj_r2_ridge)
print('The MAE is: ', mae_ridge)
print('The RMSE is: ', rmse_ridge)



######################################################

"""i) Please wirte a code piece to fit a Elastic Net Regression to the data, then print the resulting Adjusted R-squared, MAE, and RMSE metrics."""

################ EDIT CODE LINES HERE #################
# Fit elastic net regression model

from sklearn.linear_model import ElasticNetCV
# initiate the 5-Fold cross validation
elasticNet_model = ElasticNetCV(cv=5)
# fit the model with the best alpha
elasticNet_model = elasticNet_model.fit(X_train, y_train)
print('The optimal lambda is:', elasticNet_model.alpha_)
print('The optimal alpha is:', elasticNet_model.l1_ratio_)



######################################################

################ EDIT CODE LINES HERE #################

# Model predictions
y_test_pred_elasticNet = elasticNet_model.predict(X_test)
r2_elasticNet = r2_score(y_test, y_test_pred_elasticNet)
adj_r2_elasticNet = 1 - (1-r2_elasticNet) * (len(y_test)-1)/(len(y_test)-X_test.shape[1]-1)
mae_elasticNet = mean_absolute_error(y_test, y_test_pred_elasticNet)
rmse_elasticNet = mean_squared_error(y_test, y_test_pred_elasticNet, squared=False)

# Print model performance metrics
print('R-squared: ', r2_elasticNet)
print('Adjusted R-squared: ', adj_r2_elasticNet)
print('The MAE is: ', mae_elasticNet)
print('The RMSE is: ', rmse_elasticNet)




######################################################

# Defining model names and metrics
models = ['Multiple Linear Regression', 'Lasso Regression', 'Ridge Regression', 'Elastic Net Regression']
R_squared = [r2_multi, r2_lasso, r2_ridge, r2_elasticNet]
Adj_R_squared = [adj_r2_multi, adj_r2_lasso, adj_r2_ridge, adj_r2_elasticNet]
MAE = [mae_multi, mae_lasso, mae_ridge, mae_elasticNet]
RMSE = [rmse_multi, rmse_lasso, rmse_ridge, rmse_elasticNet]

# Output model performance table
modelTable = pd.DataFrame({'Model':models, 'R-squared': R_squared, 'Adj R-squared':Adj_R_squared, 'MAE': MAE, 'RMSE':RMSE})
modelTable

"""j) Compare the 4 models you just fitted. Which one turns out to be the best and why? <br ><br>(Hint: since we included 9 dummy variables in the model that are not as significant, we may be overfitting, hence leading to a negative adjusted R-squared. You can ignore the adjusted R-squared if this happens, and just compare the MAE and RMSE.)

[Write your answer here]

All of the models have extremely similar values. I choose ridge regression as it has a slightly lower MAE and RMSE.
I am ignoring the R-squared and adjusted R-squared as they were negative.

k) Based on the model you selected, write a code piece that prints the intercept and coefficient estimates, then write out the formula based on the printed output.

[Write your answer here]

The code below writes out the equation for me. Here it is copy pasted:
realGdpRate  = -0.000186937249412 + (0.000008450425740 * realPersInc) + (0.000365736675000 *
unempRate) + (0.000230024660000 * indProd) + (-0.000008001905190 * retailSales)
+ (0.000055571132300 * Country_Denmark) + (-0.000402186444000 * Country_France)
+ (0.000094523892700 * Country_Germany) + (0.000334394932000 * Country_Japan) +
(0.000813798226000 * Country_Korea) + (0.000310950823000 * Country_Luxembourg) +
(0.000226299496000 * Country_Netherlands) + (0.000037741145000 * Country_UK) +
(0.000196837853000 * Country_USA)
"""

################ EDIT CODE LINES HERE #################
# Print best model intercept and coefficients here

print('intercept:', ridge_model.intercept_)
print('coefficient:', ridge_model.coef_)




######################################################

import textwrap

# Coefficients provided
intercept = -0.00018693724941200125
coefficients = [8.45042574e-06, 3.65736675e-04, 2.30024660e-04, -8.00190519e-06,
                5.55711323e-05, -4.02186444e-04, 9.45238927e-05, 3.34394932e-04,
                8.13798226e-04, 3.10950823e-04, 2.26299496e-04, 3.77411450e-05,
                1.96837853e-04]

# Get the column names as a list
column_names_list = OECD1.columns[1:].tolist()

# Generating the regression equation as a string
regression_equation = f'y = {intercept:.15f} '
for i, coef in enumerate(coefficients):
    regression_equation += f'+ ({coef:.15f} * {column_names_list[i]}) '

# Remove the initial '+' sign and wrap the equation to 80 columns
regression_equation_wrapped = textwrap.fill(regression_equation[2:], width=80)

# Print the wrapped equation
print(regression_equation_wrapped)

"""l) What can be done to improve the Adjusted $R^2$ ?

[Write your answer here]
To improve the Adjusted R-squared value, I would usually go to using feature selection/engineering, outlier detection, and data preprocessing (exlcuding the dummy variables). However, we did all this and even used regularization with Ridge, Lasso, and Elastic Net and the features were already uncorrelated and all equally important. I would try to employ methods to pre-process the dummy variables, although I doubt they played a huge role in the final regression models. One method I though of was simply collecting more data and increasing sample size so our model can generalize better.
"""